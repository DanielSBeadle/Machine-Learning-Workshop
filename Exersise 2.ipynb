{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "655fd6ca",
   "metadata": {},
   "source": [
    "**For this task we are training a convolutional neural network to be able to label images in to different categories. We are using the python libraries tensorflow and keras for this. If you computer uses an M1 chip, you will not be able to run keras locally. To solve this you can import the .ipynb to google colab. Here you will be able to run your code without problems. For runing the code locally you will first have to install tensorflow and keras. You can do this with the commands pip install tensorflow and pip install keras.**\n",
    "\n",
    "*Image recognition tasks takes input from all the pixels in an imag. Each pixel has 3 values, one for each color in RGB. To be able to handle such a large input, and be able to detect patterns at the lowes levels we need thousands of neurons. If we were to use a traditional (fully connected) neural networ for this, the computational complexity would be ridiculously high, and the model would be very suseptable to overfitting. To solve this we are using a convolutional neural network, where neurons are connected only to neurons in close proximity.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b513b074",
   "metadata": {},
   "source": [
    "**Task 1**\n",
    "\n",
    "The dataset we are using is the cifar10 dataset. We can download it using the keras.datasets.cifar10.load_data(). The dataset is already split into training and test data, so you will have to store the output from the function in two different variables. Each of the variables will be a touple containing the RGB input values, and the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f69e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8519ec87",
   "metadata": {},
   "source": [
    "**Task 2** \n",
    "\n",
    "Our imput values for the neural network will be RGB values from 0 to 255. Convolution works best on values between 0 and 1. For that reason we want to normalize the data by dividing each value of the RGB input by 255. In tensorflow it is possible to do this by dividing the entire RGB input variable by 255 without any loops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda6d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0fa3d3",
   "metadata": {},
   "source": [
    "**Task 3**\n",
    "\n",
    "Now it is time to make the model. We can use the keras.Sequential function to add layers to the model. keras.Sequential takes a list of layers as an argument. We will start by adding six layers to demonstrate the diferent types of layers we can add to our convolution. Later you can come back to this step and customise the layers to your liking.\n",
    "\n",
    "\n",
    "3a\n",
    "\n",
    "First, let's add a convolution layer. We can add this using the function layers.Conv2D. The function takes the two arguments filters and kernel_size. kernel_size refers to how many nodes in the previous layer each neuron should be connected to. Filters refers to how many filters of neurons this layer should have. Let's use a small filter size of 16 and a 3x3 kernel_size. \n",
    "\n",
    "We will also use two optional parameters. Our convolution is two dimentional. However our input is 3 dimentional, where the third dimension is the colors (red, green, and blue). To make our layer able to deal with this input, we have to set the input_shape. Because our images has a 32x32 resolution, and we have 3 colors we should set input_shape=(32, 32, 3). \n",
    "\n",
    "The second optional parameter we should add is an activation function. By default conv2d uses a linear activation function. The activation function called relu usually performs quite well on image recognition tasks. Set activation='relu'.\n",
    "\n",
    "\n",
    "3b\n",
    "\n",
    "Now, let's add a maxpooling layer by using the layers.MaxPooling function. Maxpooling reduses the complexity of our model by combining the values of several neurons into one. The value of the new neuron is equal to the largest input value. layers.MaxPooling takes one argument, which is the pooling size. Lets go with 2x2.\n",
    " _ _\n",
    "|1|2|\n",
    " - -   =>   4\n",
    "|3|4|\n",
    " - -\n",
    " \n",
    " \n",
    "3c\n",
    "\n",
    "Let's add a second convolution layer. We can do this by doing exactly the same as in 3a. This time however, we don't have to add the input_shape argument as our data is 2 dimentional after the first convolutional layer.\n",
    "\n",
    "\n",
    "3d\n",
    "\n",
    "Now we are finished with the convolutional part of our network. The convolutional part of our network is the part that is responsible for detecting patterns in the image. The next part of our neural network is responsible for finding out what patterns translate into what labels. For this we are going to use a conventional (conected) neural network. First however, we need to flatten our network from a two dimentional network into a one dimentional network. We do this by using the layers.Flatten function. The function takes no arguments.\n",
    "\n",
    "\n",
    "3e\n",
    "\n",
    "For adding a conventional layer of neurons we can use the layers.Dense function. The function takes one argument which is the amount of neurons the layer should have. Let's go with 32. We are also going to specify an activation function for this layer. Just for fun, let's use a different one this time. Set activation='sigmoid'\n",
    "\n",
    "\n",
    "3f\n",
    "\n",
    "Lastly we should create the output layer. This is another dense layer. For this layer we need one neuron for each possible output we want the network to be able to give. Because our data have 10 different labels we should have 10 neurons in this layer. We should use the activation function 'softmax' for this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdee3382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba426dc2",
   "metadata": {},
   "source": [
    "**Task 4**\n",
    "\n",
    "Before we can fit and test the model, we have to compile it. We can do this using the .compile function. We are going to give the functio two optional parameters. Because the dataset contains integer labels we will have to give the argument loss='sparse_categorical_crossentropy'. We also want to give the argument metrics=['accuracy']. This will make the model print out it's accuracy during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73b858e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e5b970",
   "metadata": {},
   "source": [
    "**Task 5**\n",
    "\n",
    "Now let's fit the model using the .fit method. This method takes two arguments, the RGB input values of the training data, and the labels of the training data. We can use the optional argument epochs to specify how many times the model should train on training data. Doing this several times will increas how well the model is fitted to the training data. Having too may epochs can increase overfitting. Let's go with 10 for now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f380ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931a3fdb",
   "metadata": {},
   "source": [
    "**Task 6**\n",
    "\n",
    "Finally, let's evaluate the models performance by using the .evaluate function. The function takes two arguments. The RGB input values of the test data, and the labels of the test data. The evaluate function will return a list of two values. The first is the loss value, and the second one is the accuracy. For our purposes, the accuracy is what we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382bbeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
